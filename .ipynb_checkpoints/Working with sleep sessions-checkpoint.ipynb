{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bk.load\n",
    "import bk.plot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import neuroseries as nts\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import spearmanr,pearsonr\n",
    "from scipy.stats import ttest_ind, linregress\n",
    "import os\n",
    "import pl\n",
    "import re\n",
    "from itertools import chain\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "paths = pd.read_csv('Z:/All-Rats/Billel/session_indexing.csv',sep = ';')['Path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(lst, i,e):\n",
    "    return [item[i:e] for item in lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pre and post RUN sleeps\n",
    "sleep_pre=np.load('C://Users//Panagiota.Loizidou//Desktop//Amy-Hpc-sleep-dynamics-python-master//REM project//Sleeps_epochs.npy', allow_pickle=True)\n",
    "sleep_post=np.load('C://Users//Panagiota.Loizidou//Desktop//Amy-Hpc-sleep-dynamics-python-master//REM project//Sleeps_epochs_post.npy', allow_pickle=True)\n",
    "sleep=np.concatenate((sleep_pre,sleep_post), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_sleep(path, pre_RUN=True):\n",
    "    \"\"\"\n",
    "    input: the path of session you want to analyze\n",
    "    ->  all states in chronological order in the pre run period \n",
    "        all states in chronological order in the post run period \n",
    "        sleeps sessions within the desgnated period (pre or post run) that are separated by more than\n",
    "        30 seconds of wakefullness  \n",
    "    \"\"\"\n",
    "    #loading data\n",
    "    bk.load.current_session(path)\n",
    "    states=bk.load.states()\n",
    "    pre, post = bk.load.sleep()\n",
    "    \n",
    "    #turning them into a pd.DataFrame\n",
    "    wake=np.insert(np.array(states['wake'],dtype='object'),2,'wake', axis=1)\n",
    "    nrem=np.insert(np.array(states['sws'],dtype='object'), 2, 'nrem', axis=1)\n",
    "    rem=np.insert(np.array(states['Rem'],dtype='object'), 2, 'rem', axis=1)\n",
    "    drowsy=np.insert(np.array(states['drowsy'],dtype='object'), 2, 'drowsy', axis=1)\n",
    "    whole_session=np.concatenate((wake, nrem, rem, drowsy))\n",
    "    whole_session=pd.DataFrame(whole_session, columns=['start', 'stop', 'state'])\n",
    "    whole_session_sorted=whole_session.sort_values('start', ignore_index=True)\n",
    "    \n",
    "    # separating pre and post RUN\n",
    "    pre_run_period = whole_session_sorted.loc[whole_session_sorted['start']<int(pre['end'])]\n",
    "    post_run_period = whole_session_sorted.loc[whole_session_sorted['start']>int(post['start'])]\n",
    "    \n",
    "    # reseting indexing for the post run sleep session\n",
    "    post_run_period=post_run_period.reset_index(drop=True) \n",
    "    index=np.arange(0, len(post_run_period), 1)\n",
    "    post_run_period=post_run_period.reindex(index)\n",
    "    \n",
    "    # chosing which period to parse\n",
    "    if pre_RUN:\n",
    "        l=pre_run_period\n",
    "    else:\n",
    "        l=post_run_period\n",
    "       \n",
    "    p=l[(((l['stop']-l['start'])/1e6)>60) & (l['state']=='wake')]\n",
    "    k=[-1]+p.index.values.tolist()+[-1]    # list containing indexes of epochs of wake>30 s\n",
    "    \n",
    "    sleeps = [l.iloc[k[n]+1:k[n+1]] for n in range(len(k)-1)]\n",
    "    sleeps=[[i] for i in sleeps if len(i)>0] #dropping empty periods\n",
    "        \n",
    "    return pre_run_period,post_run_period, sleeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_run_period,post_run_period, sleeps = parsing_sleep(paths[10], pre_RUN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(sleep, unit='s'):\n",
    "    \"\"\"\n",
    "    input: only a specific sleep session (i.e. sleeps[0]) can be imported\n",
    "    \"\"\"\n",
    "    session=nts.IntervalSet(start=sleep[0]['start'].iloc[0], end=sleep[0]['stop'].iloc[-1])\n",
    "    return session.tot_length(unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_short_sessions(path, pre_RUN=True, duration=30, path_list=False):\n",
    "    '''\n",
    "    duration: select how long the extended sleep should be (in minutes). \n",
    "    path_list returns a list containing n times the path where n is the number of long sleeps. \n",
    "    Used later for labeling purposes \n",
    "    -> weird dataframe (np.ndarray of np.ndarray of pd.DF). Might be easier to access it using [0]\n",
    "    '''\n",
    "    _,_, sleeps=parsing_sleep(path, pre_RUN)\n",
    "    sleeps=np.array(sleeps, dtype=object)\n",
    "    index_list=[]\n",
    "    for i in range(len(sleeps)):\n",
    "        if get_duration(sleeps[i])> (duration*60):  #*60 to make it into minutes \n",
    "            index_list.append(i)\n",
    "            \n",
    "    long_sleeps=sleeps[index_list]\n",
    "    if path_list:\n",
    "        paths=[path]\n",
    "        paths=len(long_sleeps)*paths\n",
    "        return long_sleeps, paths\n",
    "    else:\n",
    "        return long_sleeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removing_short_sessions(path, pre_RUN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(path, pre_RUN=True, duration=30):\n",
    "    \"\"\"\n",
    "    -> table with average firing rates for each state lasting longer than 30 seconds of the specified session\n",
    "    \"\"\"\n",
    "    \n",
    "    session, path, rat, day,n_channels=bk.load.current_session(path, return_vars=True)\n",
    "    neurons,metadata = bk.load.loadSpikeData(bk.load.path)\n",
    "    \n",
    "    long_sleeps=removing_short_sessions(path, pre_RUN, duration)\n",
    "    durations=[]\n",
    "    rem=[]\n",
    "    starts=[]\n",
    "    stops=[]\n",
    "    states=[]\n",
    "    mean_FRs=np.zeros(len(neurons))\n",
    "    BLA_Pyr=[]\n",
    "    BLA_Int=[]\n",
    "    Hpc_Pyr=[]\n",
    "    Hpc_Int=[]\n",
    "    mean_FR=[]\n",
    "    index=[]\n",
    "    path_s=[]\n",
    "    \n",
    "    for s in range(len(long_sleeps)):\n",
    "        for i in range(len(long_sleeps[s][0])):\n",
    "            epoch=nts.IntervalSet(start=long_sleeps[s][0].iloc[i].start, end=long_sleeps[s][0].iloc[i].stop)\n",
    "            durations.append(epoch.tot_length('ms'))\n",
    "            states.append(long_sleeps[s][0].iloc[i].state)\n",
    "            starts.append(long_sleeps[s][0].iloc[i].start)\n",
    "            stops.append(long_sleeps[s][0].iloc[i].stop)\n",
    "            index.append(i)\n",
    "            \n",
    "            \n",
    "            for n in range(len(neurons)):\n",
    "                spk_time = neurons[n].restrict(epoch).as_units('s').index.values\n",
    "                mean_firing_rate= len(spk_time)/epoch.tot_length('s')\n",
    "                mean_FRs[n]=mean_firing_rate\n",
    "\n",
    "            mean_FR.append(np.nanmean(mean_firing_rate))\n",
    "            BLA_Pyr_n=np.nanmean(mean_FRs[(metadata.Region == 'BLA') & (metadata.Type == 'Pyr')])\n",
    "            BLA_Int_n=np.nanmean(mean_FRs[(metadata.Region == 'BLA') & (metadata.Type == 'Int')])\n",
    "            Hpc_Pyr_n=np.nanmean(mean_FRs[(metadata.Region == 'Hpc') & (metadata.Type == 'Pyr')])\n",
    "            Hpc_Int_n=np.nanmean(mean_FRs[(metadata.Region == 'Hpc') & (metadata.Type == 'Int')])\n",
    "            BLA_Pyr.append(float(BLA_Pyr_n))\n",
    "            BLA_Int.append(float(BLA_Int_n))\n",
    "            Hpc_Pyr.append(Hpc_Pyr_n)\n",
    "            Hpc_Int.append(Hpc_Int_n)\n",
    "    table=pd.DataFrame(np.column_stack([index, starts, stops, durations, states, mean_FR, BLA_Pyr,BLA_Int,Hpc_Pyr,Hpc_Int]), columns=['index', 'start', 'stop', 'duration', 'state', 'all_cells', 'BLA_Pyr','BLA_Int','Hpc_Pyr','Hpc_Int'])\n",
    "    for col in table.columns:\n",
    "        if col == 'state':\n",
    "            pass\n",
    "        else:\n",
    "            table[col] = table[col].astype(float)\n",
    "    \n",
    "    #adding the path column (useful if anything weird is seen)\n",
    "    table['path']=path\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_table(path, pre_RUN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_ES(path, pre_RUN=True, duration=30):\n",
    "    \"\"\"\n",
    "    parses the table of a whole sleep (pre or post run) into 'extended sleep' tables\n",
    "    *Not all sessions are supposed to have BLA and Hpc cells (because of recordings outside the BLA and Hpc)\n",
    "    \"\"\"\n",
    "    \n",
    "    sleep=get_table(path, pre_RUN, duration)\n",
    "    individual_sessions=[]\n",
    "    h=sleep[(sleep['index']==0.0)].index.values.tolist() + [len(sleep)+1]\n",
    "    j = [sleep.iloc[h[n]:h[n+1]] for n in range(len(h)-1)]\n",
    "    for u in j:\n",
    "        individual_sessions.append(u)\n",
    "    return individual_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_ES_multisession(paths=paths, pre_RUN=True, duration=30):\n",
    "    \"\"\"\n",
    "    parses into 'extended sleep' for multiple sessions but always in the same period pre or post RUN\n",
    "    \"\"\"\n",
    "    life_ruining=[] #add it to the return if you need to have it, but it is generally stable. \n",
    "                    #See list of sessions not used and reason why in Summer Internship-Part II\n",
    "    sleep=[]\n",
    "    for i in paths:\n",
    "        try:\n",
    "            sleep.append(get_table(i, pre_RUN, duration))\n",
    "        except:\n",
    "            life_ruining.append(i)\n",
    "    \n",
    "    individual_sessions=[]\n",
    "    for s in range(len(sleep)):    \n",
    "        h=sleep[s][(sleep[s]['index']==0.0)].index.values.tolist()+[-1]\n",
    "        j = [sleep[s].iloc[h[n]:h[n+1]] for n in range(len(h)-1)]\n",
    "        for u in j:\n",
    "            individual_sessions.append(u)\n",
    "    return individual_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if indeed we have only 4 states returned from the function separate_ES_multisession\n",
    "ses=separate_ES_multisession(paths=paths, pre_RUN=False)\n",
    "lst1=[]\n",
    "for i in range(len(ses)):\n",
    "    lst1.append(ses[i]['state'])\n",
    "lst2=flatten(lst1)\n",
    "set(lst2) #identifies unique elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking difference between separate_ES and removing_short_sessions\n",
    "separate_ES(path)\n",
    "removing_short_sessions(path, pre_RUN=True)\n",
    "\n",
    "# ==> removing_short_sessions is far faster because it does not call get_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the ES for all recording sessions\n",
    "longlong=[]\n",
    "longpaths=[]\n",
    "life=[]\n",
    "for i in paths:\n",
    "    try:\n",
    "        long_sleeps_pre, path_preR=removing_short_sessions(i, pre_RUN=True,min_dur=30, path_list=True)\n",
    "        path_pre = [\"PRE \" + p for p in path_preR]\n",
    "        long_sleeps_post, path_postR=removing_short_sessions(i, pre_RUN=False,min_dur=30, path_list=True)\n",
    "        path_post = [\"POST \" + p for p in path_postR]\n",
    "        long_sleeps=np.concatenate((long_sleeps_pre,long_sleeps_post))\n",
    "        paths_all=path_pre+path_post\n",
    "        longlong.extend(long_sleeps)\n",
    "        longpaths.extend(paths_all)\n",
    "        longpaths = [p.replace(\"Z:\\\\Rat\",\"\") for p in longpaths]\n",
    "        \n",
    "    except:\n",
    "        life.append(i)  #find out more about excluded sessions and reasons why in Methodology file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(life)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking that all epochs identified are consecutive without any time gaps\n",
    "for i in range(len(longlong)):\n",
    "    dur=longlong[i][0]['stop']/60e6-longlong[i][0]['start']/60e6\n",
    "    start=(longlong[i][0]['start']-longlong[i][0]['start'].iloc[0])/60e6  # subtracting start time so it starts from 0\n",
    "    start=start.tolist()\n",
    "    couples=list(zip(start, dur))\n",
    "    for i in range(1,len(couples)):\n",
    "        if couples[i][0]-couples[i-1][1]==couples[i-1][0]:\n",
    "            print('there\\'s a prob friend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'nrem':'tab:blue', 'drowsy':'tab:purple', 'rem':'tab:orange',  'wake':'tab:pink'}\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(len(longlong)):\n",
    "    dur=longlong[i][0]['stop']/60e6-longlong[i][0]['start']/60e6\n",
    "    start=(longlong[i][0]['start']-longlong[i][0]['start'].iloc[0])/60e6  # subtracting start time so it starts from 0\n",
    "    start=start.tolist()\n",
    "    couples=list(zip(start, dur))\n",
    "    \n",
    "    coloring=[]\n",
    "    for c in range(len(longlong[i][0])):   # the [0] is to get the pd.array instead of the np.ndarray\n",
    "        g=colors[longlong[i][0]['state'].iloc[c]]\n",
    "        coloring.append(g)  \n",
    "    \n",
    "    ax.broken_barh(couples, (i, 0.85), facecolors=coloring)\n",
    "\n",
    "y_pos=np.arange(0.5,len(longpaths)+0.5)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(longpaths)\n",
    "\n",
    "# adding the legend\n",
    "pop_a = mpatches.Patch(color='tab:blue', label='NREM')\n",
    "pop_b = mpatches.Patch(color='tab:orange', label='REM')\n",
    "pop_c = mpatches.Patch(color='tab:purple', label='Drowsy')\n",
    "pop_d = mpatches.Patch(color='tab:pink', label='Wake')\n",
    "\n",
    "\n",
    "plt.legend(handles=[pop_a,pop_b, pop_c, pop_d])\n",
    "\n",
    "plt.title('States in Extended Sleeps')\n",
    "plt.ylabel('Extended Sleep Session')\n",
    "plt.xlabel('Time since extended sleep onset (m)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over the Whole Recording\n",
    "Firing rate z scores calculated using means and SDs in 1-min bins over the whole recording (no separation of pre/post run).\n",
    "Includes RUN intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=paths[5]\n",
    "bk.load.current_session(path, return_vars=True)\n",
    "neurons,metadata = bk.load.loadSpikeData(bk.load.path)\n",
    "pre, post =bk.load.sleep()\n",
    "states=bk.load.states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_FR(path, region='Hpc', celltype='Pyr', min=0, max=2040, bin=1, whole=True):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    min, max, bin is in seconds\n",
    "    if whole is True, the interval will be from 0 to the end of recording. It overwrites the min and max specified.\n",
    "    -> Firing rate z scores for each cell of specified celltype at structure specified calculated using means and SDs in 1-min bins of the specified interval\n",
    "    \"\"\"\n",
    "    \n",
    "    bk.load.current_session(path)\n",
    "    neurons,metadata = bk.load.loadSpikeData(bk.load.path)\n",
    "    pre, post =bk.load.sleep()\n",
    "    \n",
    "    if whole:\n",
    "        min=pre['start'].values/1e6   # from microseconds to seconds\n",
    "        max=post['end'].values/1e6\n",
    "    \n",
    "    window = nts.IntervalSet(min,max,time_units = 's')\n",
    "    \n",
    "    n=[]\n",
    "    for i in range(len(neurons)):\n",
    "        n.append(neurons[i].restrict(window).as_units('s').index)\n",
    "    n=sorted(n,key=len)     # sorted based on highest firing rate overall \n",
    "    n=np.array(n,dtype=object)\n",
    "    \n",
    "    bins=np.arange(min,max,bin)\n",
    "    hist=[]\n",
    "    for i in range(len(neurons)):\n",
    "        j,e=np.histogram(n[i],bins)\n",
    "        hist.append(j)\n",
    "    z=zscore(hist, axis=1)\n",
    "    \n",
    "    fr_z=z[(metadata.Type==celltype) &(metadata.Region==region)]\n",
    "    \n",
    "    return fr_z, e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing over each ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing paths without any ES both for pre and post RUN\n",
    "not_use_pre=[]\n",
    "for i in range(len(paths)):\n",
    "    try:\n",
    "        ES=removing_short_sessions(paths[i])\n",
    "        if ES[0]==0:\n",
    "            not_use_pre.append(paths[i])  \n",
    "    except:\n",
    "        not_use_pre.append(paths[i])  \n",
    "useful_paths_pre=[ele for ele in paths if ele not in not_use_pre]\n",
    "# useful_paths_pre.remove(\"Z:\\Rat11\\Rat11-20150401\")\n",
    "\n",
    "not_use_post=[]\n",
    "for i in range(len(paths)):\n",
    "    try:\n",
    "        ES=removing_short_sessions(paths[i], pre_RUN=False)\n",
    "        if ES[0]==0:\n",
    "            not_use_post.append(paths[i]) \n",
    "    except:\n",
    "        not_use_post.append(paths[i])  \n",
    "useful_paths_post=[ele for ele in paths if ele not in not_use_post]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing within an ES and then selecting intervals to compare\n",
    "\n",
    "all_ES_pre=[]\n",
    "all_ES_post=[]\n",
    "first_epochs_pre=[]\n",
    "first_epochs_post=[]\n",
    "last_epochs_pre=[]\n",
    "last_epochs_post=[]\n",
    "\n",
    "for i in range(len(useful_paths_pre)): # going over all sessions\n",
    "    ES_pre=removing_short_sessions(useful_paths_pre[i])  #going over all ES in useful sessions\n",
    "    for n in range(len(ES_pre)):\n",
    "        start=ES_pre[n][0]['start'].iloc[0]/1e6\n",
    "        stop=ES_pre[n][0]['stop'].iloc[-1]/1e6\n",
    "        c, e=norm_FR(useful_paths_pre[i], min=start, max=stop, whole=False)\n",
    "        mean_c=np.nanmean((c), axis=0)\n",
    "        all_ES_pre.append(mean_c)\n",
    "        \n",
    "        if len(ES_pre)>0:\n",
    "            # getting the intervals of first and last session. Subtracting the start time:\n",
    "            start_time=ES_pre[n][0]['start'].iloc[0]\n",
    "            start_first=(ES_pre[n][0][ES_pre[n][0]['state']=='nrem'].iloc[0]['start']-start_time)/1e6\n",
    "            stop_first=(ES_pre[n][0][ES_pre[n][0]['state']=='nrem'].iloc[0]['stop']-start_time)/1e6\n",
    "            start_last=(ES_pre[n][0][ES_pre[n][0]['state']=='nrem'].iloc[-1]['start']-start_time)/1e6\n",
    "            stop_last=(ES_pre[n][0][ES_pre[n][0]['state']=='nrem'].iloc[-1]['stop']-start_time)/1e6\n",
    "            first_epoch=mean_c[int(start_first):int(stop_first)]\n",
    "            last_epoch=mean_c[int(start_last):int(stop_last)]\n",
    "            first_epochs_pre.append(first_epoch)\n",
    "            last_epochs_pre.append(last_epoch)\n",
    "\n",
    "for i in range(len(useful_paths_post)):\n",
    "    ES_post=removing_short_sessions(useful_paths_post[i], pre_RUN=False)\n",
    "    for n in range(len(ES_post)):\n",
    "        start=ES_post[n][0]['start'].iloc[0]/1e6\n",
    "        stop=ES_post[n][0]['stop'].iloc[-1]/1e6\n",
    "        c, e=norm_FR(useful_paths_post[i], min=start, max=stop, whole=False)\n",
    "        mean_c=np.nanmean((c), axis=0)\n",
    "        all_ES_post.append(mean_c)\n",
    "        \n",
    "        if len(ES_post)>0:\n",
    "            # getting the intervals of first and last sessions:\n",
    "            start_time=ES_post[n][0]['start'].iloc[0]\n",
    "            start_first=(ES_post[n][0][ES_post[n][0]['state']=='nrem'].iloc[0]['start']-start_time)/1e6\n",
    "            stop_first=(ES_post[n][0][ES_post[n][0]['state']=='nrem'].iloc[0]['stop']-start_time)/1e6\n",
    "            start_last=(ES_post[n][0][ES_post[n][0]['state']=='nrem'].iloc[-1]['start']-start_time)/1e6\n",
    "            stop_last=(ES_post[n][0][ES_post[n][0]['state']=='nrem'].iloc[-1]['stop']-start_time)/1e6\n",
    "            first_epoch=mean_c[int(start_first):int(stop_first)]\n",
    "            last_epoch=mean_c[int(start_last):int(stop_last)]\n",
    "            first_epochs_post.append(first_epoch)\n",
    "            last_epochs_post.append(last_epoch)\n",
    "        \n",
    "all_ES=all_ES_pre+all_ES_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing how z-scored FR looks like\n",
    "for i in range(len(all_ES)):\n",
    "    plt.scatter(np.arange(len(all_ES[i])),all_ES[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_t=[]\n",
    "for i in range(len(all_ES)):\n",
    "    fr_t.extend(list(zip(all_ES[i], np.arange(len(all_ES[i])))))\n",
    "    \n",
    "a=np.array(fr_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing nan values\n",
    "filt = np.isfinite(a[:,0])\n",
    "y = a[filt,0]\n",
    "x = a[filt,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression\n",
    "slope, intercept, r, p, se=linregress(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the linear regression fitted line\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x, intercept + slope*x, 'r', label='fitted line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_Line(path=path, neurons=neurons,metadata=metadata,region='Hpc', celltype='Pyr',state='Rem', min=0, max=2040, bin=1, whole=True):\n",
    "    g, bins=separate_States_Epochs(path, neurons,metadata,region, celltype,state, min, max, bin, whole)\n",
    "    slopes=[]\n",
    "    y_preds=[]\n",
    "    for i in np.arange(len(bins)):\n",
    "        x=np.array(zscore(bins[i])).reshape((-1,1))  #normalizing x (y is already z-scored)\n",
    "        y=np.array(g[i])\n",
    "        model = LinearRegression()\n",
    "        model.fit(x, y)\n",
    "        model = LinearRegression().fit(x, y)\n",
    "        r_sq = model.score(x, y)\n",
    "        slopes.append(model.coef_)\n",
    "        intercept=model.intercept_ #not useful\n",
    "        y_preds.append(model.predict(x))\n",
    "    return g, bins, slopes, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(flatten(last_epochs_pre), flatten(first_epochs_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_ES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(flatten(last_epochs_post), flatten(first_epochs_post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(last_epochs_post[5])\n",
    "plt.plot(first_epochs_pre[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ES_pre=removing_short_sessions(useful_paths_pre[0])  #going over all ES in useful sessions\n",
    "start=ES_pre[0][0]['start'].iloc[0]/1e6\n",
    "stop=ES_pre[0][0]['stop'].iloc[-1]/1e6\n",
    "c, e=norm_FR(useful_paths_pre[0], min=start, max=stop, whole=False)\n",
    "mean_c=np.nanmean((c), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing pre and post FR\n",
    "ttest_ind(flatten(first_epochs_post), flatten(first_epochs_pre)) \n",
    "ttest_ind(flatten(last_epochs_post), flatten(last_epochs_pre)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plotting firing rates (z-score) for single sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session, path, rat, day,n_channels=bk.load.current_session(paths[3],return_vars=True)\n",
    "neurons,metadata = bk.load.loadSpikeData(bk.load.path)\n",
    "pre, post =bk.load.sleep()\n",
    "states=bk.load.states()\n",
    "region='Hpc'\n",
    "celltype='Pyr'\n",
    "c,e=norm_FR(paths[3],region, celltype, min=0, max=2040, bin=60, whole=True)\n",
    "# c=np.mean(v, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(c[1])\n",
    "bk.plot.intervals(states['Rem']/60, col = 'blue', alpha=0.3)\n",
    "# bk.plot.intervals(states['wake']/60, col = 'r', alpha=0.3)\n",
    "# bk.plot.intervals(states['drowsy']/60, col = 'g', alpha=0.3)\n",
    "bk.plot.intervals(states['sws']/60, col = 'red', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Single Session Firing Rate (z-score)')\n",
    "plt.title('Session: '+str(session) +', Rat: '+ str(rat) +', Day: '+  str(day)+', Region: '+ region+', Celltype: '+ celltype)\n",
    "plt.ylabel('Normalized Firing Rate (z)')\n",
    "plt.xlabel('1-min Timebins (m)')\n",
    "\n",
    "REM_patch = mpatches.Patch(color = 'blue', alpha=0.3, label='REM')\n",
    "NREM_patch = mpatches.Patch(color = 'red', alpha=0.3, label='NREM')\n",
    "plt.legend(handles=[REM_patch, NREM_patch])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h=[]\n",
    "# life=[]\n",
    "# for i in range(len(paths)):\n",
    "#     try:\n",
    "#         v,e=norm_FR(paths[i],region='Hpc', celltype='Pyr', min=0, max=2040, bin=60, whole=True)\n",
    "#         c=np.mean(v, axis=0)\n",
    "#         h.append(c)\n",
    "#     except:\n",
    "#         life.append(paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s=long_sleeps[0][0]['start'][long_sleeps[0][0]['state']=='nrem'].tolist()\n",
    "# f=long_sleeps[0][0]['stop'][long_sleeps[0][0]['state']=='nrem'].tolist()\n",
    "# for start, finish in zip(s,f):\n",
    "#     plt.axvspan(start/60e6,finish/60e6, facecolor='b', alpha=0.1)\n",
    "# s=long_sleeps[0][0]['start'][long_sleeps[0][0]['state']=='rem'].tolist()\n",
    "# f=long_sleeps[0][0]['stop'][long_sleeps[0][0]['state']=='rem'].tolist()\n",
    "# for start, finish in zip(s,f):\n",
    "#     plt.axvspan(start/60e6,finish/60e6, facecolor='r', alpha=0.1)\n",
    "# plt.plot(np.mean(fr[0], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_FR_sessionLoaded(path=path, neurons=neurons,metadata=metadata,region='Hpc', celltype='Pyr', min=0, max=2040, bin=60, whole=True):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    min, max, bin is in seconds\n",
    "    if whole is True, the interval will be from 0 to the end of recording. It overwrites the min and max specified.\n",
    "    -> Firing rate z scores for the celltypes at structure specified calculated using means and SDs in 1-min bins of the specified interval\n",
    "    \"\"\"\n",
    "    \n",
    "    if whole:\n",
    "        min=pre['start'].values/1e6\n",
    "        max=post['end'].values/1e6\n",
    "    window = nts.IntervalSet(min,max,time_units = 's')\n",
    "    \n",
    "    n=[]\n",
    "    for i in range(len(neurons)):\n",
    "        n.append(neurons[i].restrict(window).as_units('s').index)\n",
    "#     n=sorted(n,key=len)\n",
    "    n=np.array(n,dtype=object)\n",
    "    \n",
    "    bins=np.arange(min,max,bin)\n",
    "    hist=[]\n",
    "    for i in range(len(neurons)):\n",
    "        j,e=np.histogram(n[i],bins)\n",
    "        hist.append(j)\n",
    "    z=zscore(hist, axis=1)\n",
    "    \n",
    "    c=z[(metadata.Type==celltype) &(metadata.Region==region)]\n",
    "    \n",
    "    return c,e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, e=norm_FR_sessionLoaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(c[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(c[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_FR_noRUN_sessionLoaded(path=path, neurons=neurons,metadata=metadata,region='Hpc', celltype='Pyr', min=0, max=2040, bin=60, whole=True):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    min, max, bin is in seconds\n",
    "    if whole is True, the interval will be from 0 to the end of recording WITHOUT TAKING INTO ACCOUNT THE RUN SESSION. It overwrites the min and max specified.\n",
    "    -> Firing rate z scores for the celltypes at structure specified calculated using means and SDs in 1-min bins of the specified interval\n",
    "    \"\"\"\n",
    "    \n",
    "    if whole:\n",
    "        min=pre['start'].values/1e6\n",
    "        min_2=post['start'].values/1e6\n",
    "        max=pre['end'].values/1e6\n",
    "        max_2=post['end'].values/1e6\n",
    "        \n",
    "    window = nts.IntervalSet([min, min_2],[max, max_2],time_units = 's')\n",
    "    \n",
    "    n=[]\n",
    "    for i in range(len(neurons)):\n",
    "        n.append(neurons[i].restrict(window).as_units('s').index)\n",
    "#     n=sorted(n,key=len)\n",
    "    n=np.array(n,dtype=object)\n",
    "    \n",
    "    bins_pre=np.arange(min,max,bin).tolist()\n",
    "    bins_post=np.arange(min_2,max_2,bin).tolist()\n",
    "    bins=bins_pre+bins_post\n",
    "    hist=[]\n",
    "    for i in range(len(neurons)):\n",
    "        j,e=np.histogram(n[i],bins)\n",
    "        hist.append(j)\n",
    "    z=zscore(hist, axis=1)\n",
    "    \n",
    "    c=z[(metadata.Type==celltype) &(metadata.Region==region)]\n",
    "    \n",
    "    return c,e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def norm_FR_noRUN_sessionLoaded_withinState(path=path, neurons=neurons,metadata=metadata,region='Hpc', celltype='Pyr', min=0, max=2040, bin=60, whole=True):\n",
    "#     \"\"\"\n",
    "#     inputs:\n",
    "#     min, max, bin is in seconds\n",
    "#     if whole is True, the interval will be from 0 to the end of recording WITHOUT TAKING INTO ACCOUNT THE RUN SESSION. It overwrites the min and max specified.\n",
    "#     -> Firing rate z scores for the celltypes at structure specified calculated using means and SDs in 1-min bins of the specified interval. \n",
    "#     ***normalization performed within each state: i.e. the avg of all nrem states within an ext. sleep will be 0***\n",
    "#     \"\"\"\n",
    "    \n",
    "#     if whole:\n",
    "#         min=pre['start'].values/1e6\n",
    "#         min_2=post['start'].values/1e6\n",
    "#         max=pre['end'].values/1e6\n",
    "#         max_2=post['end'].values/1e6\n",
    "        \n",
    "#     window = nts.IntervalSet([min, min_2],[max, max_2],time_units = 's')\n",
    "    \n",
    "#     n=[]\n",
    "#     for i in range(len(neurons)):\n",
    "#         n.append(neurons[i].restrict(window).as_units('s').index)\n",
    "# #     n=sorted(n,key=len)\n",
    "#     n=np.array(n,dtype=object)\n",
    "    \n",
    "#     bins_pre=np.arange(min,max,bin).tolist()\n",
    "#     bins_post=np.arange(min_2,max_2,bin).tolist()\n",
    "#     bins=bins_pre+bins_post\n",
    "#     hist=[]\n",
    "#     for i in range(len(neurons)):\n",
    "#         j,e=np.histogram(n[i],bins)\n",
    "#         hist.append(j)\n",
    "#     z=zscore(hist, axis=1)\n",
    "    \n",
    "#     c=z[(metadata.Type==celltype) &(metadata.Region==region)]\n",
    "    \n",
    "#     return c,e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# under construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=states['Rem']['start'][states['Rem']['start']>12692000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_FR_noRUN_sessionLoaded_withinState(path=path, neurons=neurons,metadata=metadata,region='Hpc', celltype='Pyr',state='Rem', min=0, max=2040, bin=1, whole=True):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    state= choose between 'Rem', 'sws','drowsy', 'wake'\n",
    "    min, max, bin is in seconds\n",
    "    if whole is True, the interval will be from 0 to the end of recording WITHOUT TAKING INTO ACCOUNT THE RUN SESSION. It overwrites the min and max specified.\n",
    "    -> Firing rate z scores for the celltypes at structure specified calculated using means and SDs in 1-min bins of the specified interval. \n",
    "    ***normalization performed within each state: i.e. the avg of all nrem states within a sleep session will be 0***\n",
    "    \"\"\"\n",
    "    \n",
    "    #selecting interesting neurons\n",
    "    neurons=neurons[(metadata.Type==celltype) &(metadata.Region==region)]\n",
    "    \n",
    "    \n",
    "    if whole:\n",
    "        min=pre['start'].values/1e6\n",
    "        min_2=post['start'].values/1e6\n",
    "        max=pre['end'].values/1e6\n",
    "        max_2=post['end'].values/1e6\n",
    "\n",
    "    window = nts.IntervalSet([min, min_2],[max, max_2],time_units = 's')\n",
    "\n",
    "\n",
    "    #creating an interval window for the state chosen\n",
    "    state=states[state].values/1e6\n",
    "    state_start=[]\n",
    "    state_end=[]\n",
    "    for i in state:\n",
    "        state_start.append(i[0])\n",
    "        state_end.append(i[1])\n",
    "\n",
    "    window = nts.IntervalSet(state_start,state_end,time_units = 's')\n",
    "    \n",
    "    #taking the FR of each neuron within the window of each state\n",
    "    n=[]\n",
    "    for i in range(len(neurons)):\n",
    "        n.append(neurons[i].restrict(window).as_units('s').index)\n",
    "    n=np.array(n,dtype=object)\n",
    "    \n",
    "    #creating bins in order to extract the firing rate of each neuron. binsize specified above \n",
    "    bins=[]\n",
    "    for i in state:\n",
    "        edges=np.arange(i[0],i[1],bin).tolist()\n",
    "        bins.append(edges)\n",
    "    bins_flat=flatten(bins)\n",
    "    \n",
    "    #extractin firing rate/bin\n",
    "    hist=[]\n",
    "    for i in range(len(neurons)):\n",
    "        j,_=np.histogram(n[i],bins_flat)\n",
    "        hist.append(j)\n",
    "        \n",
    "    #normalizing (z-scoring)\n",
    "    fr_z=zscore(hist, axis=1)\n",
    "\n",
    "    \n",
    "    #fr_z is the z-scored firing rate for each neuron in the epoch designated \n",
    "    #bins_flat is all the seconds in the specified state in this ES\n",
    "    #bins is all the seconds in the ES binned in separate epochs (for instance the first REM epoch in the ES is bins[0])\n",
    "    return fr_z,bins_flat,bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_FR_noRUN_sessionLoaded_withinState(path=path, neurons=neurons,metadata=metadata,region='Hpc', celltype='Pyr',state='Rem',min=start, max=stop, bin=1, whole=False):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ES=removing_short_sessions(paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ES=removing_short_sessions(paths[0])\n",
    "start=ES[0][0]['start'].iloc[0]\n",
    "stop=ES[0][0]['stop'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_z,bins_flat,bins=norm_FR_noRUN_sessionLoaded_withinState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bins_flat[0:-1], np.mean(fr_z, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_States_Epochs(path=path, neurons=neurons,metadata=metadata,region='Hpc', celltype='Pyr',state='Rem', min=0, max=2040, bin=1, whole=True):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\"\n",
    "    \n",
    "    fr_z, bins_flat, bins=norm_FR_noRUN_sessionLoaded_withinState(path, neurons,metadata,region, celltype,state, min, max, bin, whole)\n",
    "    \n",
    "    g=[] #average fr for each second in each epoch\n",
    "    counter=0\n",
    "    for i in np.arange(len(bins)):\n",
    "        fr_ep=extract(fr_z,counter,counter+len(bins[i]))\n",
    "        counter+=int(len(bins[i]))\n",
    "        g.append(np.mean(fr_ep, axis=0))\n",
    "    \n",
    "    del bins[-1][-1]\n",
    "    return g, bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, bins=separate_States_Epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=flatten(g)\n",
    "k = flatten(bins)\n",
    "len(k)\n",
    "plt.plot(k,l)\n",
    "np.mean(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_0=[]\n",
    "g_last=[]\n",
    "for i in paths:\n",
    "    g, _=separate_States_Epochs(path=i)\n",
    "    g_0.append(g[0])\n",
    "    g_last.append(g[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_0=flatten(g_0)\n",
    "g_last=flatten(g_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(g_0, g_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(k,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(len(paths)):\n",
    "    kill=[]\n",
    "    avg_avg=[]\n",
    "    try:\n",
    "        bk.load.current_session(paths[i], return_vars=True)\n",
    "        neurons,metadata = bk.load.loadSpikeData(bk.load.path)\n",
    "        pre, post =bk.load.sleep()\n",
    "        states=bk.load.states()\n",
    "        g, bins, slopes, y_preds= regression_Line()\n",
    "        slope_list=[]\n",
    "        for i in np.arange(len(g)):\n",
    "            plt.plot(bins[i],y_preds[i])\n",
    "            plt.scatter(bins[i],g[i])\n",
    "            slope_list.append(slopes[i])\n",
    "        avg=np.mean(slope_list)\n",
    "        avg_avg.append(avg)\n",
    "    except:\n",
    "        kill.append(paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_list=[]\n",
    "for i in np.arange(len(g)):\n",
    "    plt.plot(bins[i],y_preds[i])\n",
    "    plt.scatter(bins[i],g[i])\n",
    "    slope_list.append(slopes[i])\n",
    "avg=np.mean(slope_list)\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression [only to play with, not used]\n",
    "transformer = PolynomialFeatures(degree=2, include_bias=False)\n",
    "transformer.fit(x)\n",
    "x_ = transformer.transform(x)\n",
    "x_ = PolynomialFeatures(degree=3, include_bias=False).fit_transform(x)\n",
    "model = LinearRegression()\n",
    "model.fit(x_, y)\n",
    "model = LinearRegression().fit(x_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, bins=norm_FR_noRUN_sessionLoaded_withinState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,e,_=norm_FR_noRUN_sessionLoaded_withinState()\n",
    "c_1,e_1,_=norm_FR_noRUN_sessionLoaded_withinState(region='BLA', celltype='Pyr')\n",
    "c_2,e_2,_=norm_FR_noRUN_sessionLoaded_withinState(state='sws')\n",
    "c_3,e_3,_=norm_FR_noRUN_sessionLoaded_withinState(state='sws',region='BLA', celltype='Pyr')\n",
    "g=np.mean(c, axis=0)\n",
    "g_1=np.mean(c_1, axis=0)\n",
    "g_2=np.mean(c_2, axis=0)\n",
    "g_3=np.mean(c_3, axis=0)\n",
    "plt.plot(e[:-1], g)\n",
    "plt.plot(e_1[:-1], g_1)\n",
    "plt.plot(e_2[:-1], g_2)\n",
    "plt.plot(e_3[:-1], g_3)\n",
    "plt.title(\"Avg firing rate selected neurons in the state selected (z-score obtained based on firing rates during x)\")\n",
    "bk.plot.intervals(states['Rem'], col = 'blue', alpha=0.3)\n",
    "# bk.plot.intervals(states['wake']/60, col = 'r', alpha=0.3)\n",
    "# bk.plot.intervals(states['drowsy']/60, col = 'g', alpha=0.3)\n",
    "bk.plot.intervals(states['sws'], col = 'red', alpha=0.3)\n",
    "REM_patch = mpatches.Patch(color = 'blue', alpha=0.3, label='REM')\n",
    "NREM_patch = mpatches.Patch(color = 'red', alpha=0.3, label='NREM')\n",
    "plt.legend(handles=[REM_patch, NREM_patch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot graphs of spikes and z-score run included\n",
    "c, e=norm_FR_sessionLoaded(paths[6], neurons)\n",
    "plt.figure()\n",
    "plt.eventplot(neurons[0].restrict(post).index/60e6-pre['start'].values/60e6, alpha=0.2, label='spike train')\n",
    "plt.eventplot(neurons[0].restrict(pre).index/60e6-pre['start'].values/60e6, alpha=0.2)\n",
    "plt.plot(c[0], c='orange',linewidth=3, label='normalized firing rate')\n",
    "plt.axvspan(pre['end'].values/60e6-pre['start'].values/60e6, post['start'].values/60e6-pre['start'].values/60e6, facecolor='g', alpha=0.2, label='run')\n",
    "plt.ylabel('Firing Rate (z)')\n",
    "plt.xlabel('Time since session startes (mins)')\n",
    "plt.legend()\n",
    "plt.title('Example of normalized firing rate as compared to the spike train of the same neuron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot graphs of spikes and z-score run NOT included\n",
    "c, e=norm_FR_noRUN_sessionLoaded(paths[5], neurons)\n",
    "plt.figure()\n",
    "plt.eventplot(neurons[103].restrict(post).index/60e6-(post['start'].values-pre['end'].values+pre['start'].values)/60e6, alpha=0.2, label='spike train')\n",
    "plt.eventplot(neurons[103].restrict(pre).index/60e6-pre['start'].values/60e6, alpha=0.2)\n",
    "plt.plot(c[103], c='orange',linewidth=2.5, label='normalized firing rate')\n",
    "plt.axvspan(pre['start'].values/60e6-pre['start'].values/60e6, pre['end'].values/60e6-pre['start'].values/60e6, facecolor='g', alpha=0.2, label='pre-run')\n",
    "plt.ylabel('Firing Rate (z)')\n",
    "plt.xlabel('Time since session startes (mins)')\n",
    "plt.legend()\n",
    "plt.title('Example of normalized firing rate as compared to the spike train of the same neuron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing within each epoch, taking the mean of all neurons during each epoch and plotting them against the time since the start of sleep session\n",
    "\n",
    "problematic because comparing mean z-scores obtained by different periods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fav(path, region='Hpc', celltype='Pyr', pre_RUN=True):\n",
    "    bk.load.current_session(path)\n",
    "    neurons,metadata = bk.load.loadSpikeData(bk.load.path)\n",
    "    pre, post =bk.load.sleep()\n",
    "    \n",
    "    if type(path)==str:\n",
    "        fr=[]\n",
    "        long_sleeps=removing_short_sessions(path, pre_RUN)\n",
    "        for s in range(len(long_sleeps)): #for each sleep session\n",
    "            for e in range(len(long_sleeps[s][0])): #for each state/epoch in sleep \n",
    "                c,et=norm_FR_sessionLoaded(path,neurons, metadata, region, celltype, min=long_sleeps[s][0]['start'].iloc[e]/1e6, max=long_sleeps[s][0]['stop'].iloc[e]/1e6, bin=60, whole=False)\n",
    "                fr.append(c)\n",
    "#     else:\n",
    "#         long_sleeps=[]\n",
    "#         fr=[]\n",
    "#         for p in path:\n",
    "#             long=removing_short_sessions(p, pre_RUN)\n",
    "#             long_sleeps.extend(long)\n",
    "#             for s in range(len(long_sleeps)):\n",
    "#                 for e in range(len(long_sleeps[s])):\n",
    "#                     c=norm_FR(p, region, celltype, min=long_sleeps[s][0]['start'].iloc[e]/1e6, max=long_sleeps[s][0]['stop'].iloc[e]/1e6, bin=60, whole=False)\n",
    "#                     fr.append(c)\n",
    "    return long_sleeps, fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk.load.current_session(paths[4])\n",
    "neurons,metadata = bk.load.loadSpikeData(bk.load.path)\n",
    "pre, post =bk.load.sleep()\n",
    "states=bk.load.states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_sleeps_all, fr=fav(paths[4], region='Hpc', celltype='Pyr', pre_RUN=True)\n",
    "long_sleeps=long_sleeps_all[0][0].reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_sleeps_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=[np.nanmean(fr[i], axis=0) for i in range(len(fr))]\n",
    "f=np.array(f[0:len(long_sleeps)])\n",
    "g=f[long_sleeps.state=='rem']\n",
    "\n",
    "g=[np.nanmean(g[i]) for i in range(len(g))]  #taking the mean of each epoch\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter((long_sleeps[long_sleeps.state=='rem']['start']-long_sleeps['start'][0])/60e6,g)\n",
    "plt.ylabel('Firing Rate (z)')\n",
    "plt.xlabel('Timebins (mins)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing for whole session, taking the mean of all neurons during each epoch and plotting them against the time since the start of sleep session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fav(path, region='Hpc', celltype='Pyr', pre_RUN=True, duration=30):\n",
    "    bk.load.current_session(path)\n",
    "    neurons,metadata = bk.load.loadSpikeData(bk.load.path)\n",
    "    pre, post =bk.load.sleep()\n",
    "    \n",
    "    if type(path)==str:\n",
    "        fr=[]\n",
    "        long_sleeps=removing_short_sessions(path, pre_RUN, duration)\n",
    "        for s in range(len(long_sleeps)): #for each sleep session\n",
    "            for e in range(len(long_sleeps[s][0])): #for each state/epoch in sleep \n",
    "                c,et=norm_FR_noRUN_sessionLoaded(path,neurons, metadata, region, celltype, min=long_sleeps[s][0]['start'].iloc[e]/1e6, max=long_sleeps[s][0]['stop'].iloc[e]/1e6, bin=60, whole=False)\n",
    "                fr.append(c)\n",
    "#     else:\n",
    "#         long_sleeps=[]\n",
    "#         fr=[]\n",
    "#         for p in path:\n",
    "#             long=removing_short_sessions(p, pre_RUN)\n",
    "#             long_sleeps.extend(long)\n",
    "#             for s in range(len(long_sleeps)):\n",
    "#                 for e in range(len(long_sleeps[s])):\n",
    "#                     c=norm_FR(p, region, celltype, min=long_sleeps[s][0]['start'].iloc[e]/1e6, max=long_sleeps[s][0]['stop'].iloc[e]/1e6, bin=60, whole=False)\n",
    "#                     fr.append(c)\n",
    "    return long_sleeps, fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final(path=paths[5],neurons=neurons, metadata=metadata, region='Hpc', celltype='Pyr',state='nrem', min=0, max=90, bin=60, whole=True, duration=30):\n",
    "    bk.load.current_session(path)\n",
    "    neurons,metadata = bk.load.loadSpikeData(bk.load.path)\n",
    "    pre, post =bk.load.sleep()\n",
    "    states=bk.load.states()\n",
    "    \n",
    "    c,e=norm_FR_noRUN_sessionLoaded(path,neurons, metadata, region, celltype, min, max, bin, whole) # c is normalized fr for each neuron, e is the timebins used for normalization\n",
    "    r=np.mean(c, axis=0) #r is the average z of all cells per timebin\n",
    "    timepoints=np.array(list(zip(r,e)))\n",
    "    \n",
    "    l=[] #list of sleeps\n",
    "    long_sleeps_pre=removing_short_sessions(path, pre_RUN=True, duration)\n",
    "    long_sleeps_post=removing_short_sessions(path, pre_RUN=False, duration)\n",
    "    if len(long_sleeps_pre)>0 and len(long_sleeps_post)==0:\n",
    "        long_sleeps=long_sleeps_pre\n",
    "    elif len(long_sleeps_post)>0 and len(long_sleeps_pre)==0:\n",
    "        long_sleeps=long_sleeps_post\n",
    "    else:\n",
    "        long_sleeps=np.concatenate((long_sleeps_pre,long_sleeps_post))\n",
    "    \n",
    "    for i in range(len(long_sleeps)):\n",
    "        ls=long_sleeps[i][0].reset_index(drop=True) \n",
    "        l.append(ls)\n",
    "    state_fr=[]\n",
    "    fr=[]\n",
    "    t_state=[]\n",
    "    for i in range(len(l)):    \n",
    "        bin_start=(l[i]['start']/1e6).tolist()       \n",
    "        bin_start.append(l[i]['stop'].iloc[-1]/1e6) #adding the last end of the extended sleep\n",
    "        f,_=np.histogram(timepoints[:,1],bin_start)       #how many timepoints are in each epoch\n",
    "        p=0\n",
    "        index=[0]\n",
    "        for c in f:\n",
    "            p+=c\n",
    "            index.append(p)\n",
    "        f=[r[index[h]:index[h+1]] for h in range(len(index)-1)]\n",
    "        fr.append(f)\n",
    "        w=np.array([np.mean(f[u]) for u in range(len(f))]) \n",
    "        nrem=w[l[i]['state']==state].tolist()\n",
    "        times=(((l[i]['start'][l[i]['state']==state]+l[i]['stop'][l[i]['state']==state])/2)-l[i]['start'][0])/1e6  #taking the midpoint of an epoch\n",
    "        t_state.append(times)\n",
    "        state_fr.append(nrem)\n",
    "        \n",
    "    return state_fr,t_state, fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fr,t_state, fr = final(paths[56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(flatten(t_state), flatten(state_fr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_rem=[]\n",
    "t_rem=[]\n",
    "fre_rem=[]\n",
    "\n",
    "cest_la_vie=[]\n",
    "for i in range(len(paths)):\n",
    "    try:\n",
    "        op,t, fre=final(paths[i], region='BLA',state='rem')\n",
    "        op_rem.extend(op)\n",
    "        t_rem.extend(t)\n",
    "        fre_rem.extend(fre)\n",
    "        \n",
    "    except:\n",
    "        cest_la_vie.append(paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cest_la_vie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe, corr, spear=cuantilization(op_rem, t_rem, cell='pyramidal', structure='BLA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_nrem=[]\n",
    "t_nrem=[]\n",
    "fre_nrem=[]\n",
    "\n",
    "cest_la_vie=[]\n",
    "for i in range(len(paths)):\n",
    "    try:\n",
    "        op,t, fre=final(paths[i], state='nrem')\n",
    "        op_rem.extend(op)\n",
    "        t_rem.extend(t)\n",
    "        fre_rem.extend(fre)\n",
    "        \n",
    "    except:\n",
    "        cest_la_vie.append(paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_dro=[]\n",
    "t_dro=[]\n",
    "fre_dro=[]\n",
    "\n",
    "cest_la_vie=[]\n",
    "for i in range(len(paths)):\n",
    "    try:\n",
    "        op,t, fre=final(paths[i], state='drowsy')\n",
    "        op_rem.extend(op)\n",
    "        t_rem.extend(t)\n",
    "        fre_rem.extend(fre)\n",
    "        \n",
    "    except:\n",
    "        cest_la_vie.append(paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuantilization(op_a, t_a, bins=100, state='REM', cell='pyramidal', structure='Hpc'):\n",
    "    fio=list(chain.from_iterable(t_a))\n",
    "    fiu=list(chain.from_iterable(op_a))\n",
    "    data_tuples=list(zip(fiu, fio))\n",
    "    dataframe=pd.DataFrame(data_tuples, columns=['fr', 'timing'])\n",
    "    bin_times=pd.cut(dataframe['timing'], bins)\n",
    "    o=[bin_times[i].mid for i in range(len(bin_times))]\n",
    "    data_tuples=list(zip(fiu, fio, o))\n",
    "    dataframe=pd.DataFrame(data_tuples, columns=['fr', 'timing', 'mid'])\n",
    "    quantiles=pd.qcut(dataframe['timing'].values, bins, labels=np.arange(0,bins,1))\n",
    "    data_tuples=list(zip(fiu, fio,bin_times, o, quantiles))\n",
    "    dataframe=pd.DataFrame(data_tuples, columns=['fr', 'timing', 'bins', 'mid', 'quantiles'])\n",
    "    f=dataframe.groupby('quantiles')['fr'].mean()\n",
    "    t=dataframe.groupby('quantiles')['timing'].mean()\n",
    "    \n",
    "    fr_mid=list(zip(dataframe['fr'], dataframe['mid']))\n",
    "    fr_mid=pd.DataFrame(fr_mid, columns=['fr', 'mid'])\n",
    "    fr_mid=fr_mid[~dataframe['fr'].isna()]\n",
    "    m, b = np.polyfit(fr_mid['mid'], fr_mid['fr'], 1)\n",
    "\n",
    "    \n",
    "    f_tuples=list(zip(dataframe['mid'], dataframe['fr']))\n",
    "    f_df=pd.DataFrame(f_tuples, columns=['mid','fr'])\n",
    "    corr=f_df.corr()\n",
    "    \n",
    "    spear=spearmanr(dataframe['mid'], dataframe['fr'], nan_policy='omit')\n",
    "    \n",
    "    plt.scatter(t/60,f)\n",
    "    plt.plot(t/60, m*t + b)\n",
    "    plt.title('Mean firing rate of '+ cell + ' cells in the '+ structure +' during '+state)\n",
    "    plt.ylabel('Firing Rate (z)')\n",
    "    plt.xlabel('Time from onset of ES (min)')\n",
    "    plt.text(50, -0.3, r'$r_s$: '+str(np.around(spear[0], 3))+'\\n'+ 'p: '+str(\"{:.2e}\".format(spear[1]))+ '\\n'+ 'Pearsons r: ' +str(np.around(corr['fr']['mid'], 3)))\n",
    "    plt.show()\n",
    "    \n",
    "    return dataframe, corr, spear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe, corr, spear=quantilization(op_, t_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fio=list(chain.from_iterable(t_rem))\n",
    "fiu=list(chain.from_iterable(op_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuples=list(zip(fiu, fio))\n",
    "dataframe=pd.DataFrame(data_tuples, columns=['fr', 'timing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_times=pd.cut(dataframe['timing'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=[bin_times[i].mid for i in range(len(bin_times))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuples=list(zip(fiu, fio,o))\n",
    "dataframe=pd.DataFrame(data_tuples, columns=['fr', 'timing', 'mid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles=pd.qcut(dataframe['timing'].values, 10, labels=np.arange(0,10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuples=list(zip(fiu, fio,bin_times, o, quantiles))\n",
    "dataframe=pd.DataFrame(data_tuples, columns=['fr', 'timing', 'bins', 'mid', 'quantiles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=dataframe.groupby('quantiles')['fr'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=dataframe.groupby('quantiles')['timing'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_mid=list(zip(dataframe['fr'], dataframe['mid']))\n",
    "fr_mid=pd.DataFrame(fr_mid, columns=['fr', 'mid'])\n",
    "fr_mid=fr_mid[~dataframe['fr'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, b = np.polyfit(fr_mid['mid'], fr_mid['fr'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(t,f)\n",
    "plt.plot(t, m*t + b)\n",
    "plt.title()\n",
    "plt.ylabel('Firing Rate (z)')\n",
    "plt.xlabel('Time from onset of ES (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_tuples=list(zip(dataframe['mid'], dataframe['fr']))\n",
    "f_df=pd.DataFrame(f_tuples, columns=['mid','fr'])\n",
    "f_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(f_df)\n",
    "\n",
    "plt.ylabel('Firing Rate (z)')\n",
    "plt.xlabel('Timebins (mins)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr(dataframe['mid'], dataframe['fr'], nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['fr']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
